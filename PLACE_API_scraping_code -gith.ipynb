{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "#pd.set_option('display.max_column', None)\n",
    "#pd.set_option('display.max_row', None)\n",
    "#pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` GEOCODE API```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = os.getenv()\n",
    "gm = googlemaps.Client('API_KEY')\n",
    "gm_result = gm.geocode('pizza near ipoh') # it returns the coordinate of location, not places\n",
    "gm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```MAIN API```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoloc_geocode_place_api = 'API_KEY'\n",
    "gm_geoloc = googlemaps.Client(key=geoloc_geocode_place_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```----TEST START---------```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"pizza in Batu Pahat\"\n",
    "test_geo_place = gm_geoloc.places(test, radius=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_geo_place['results'][0]['plus_code']['compound_code'].split(' '))\n",
    "\n",
    "# test_geo_place['results'] -- type list\n",
    "# test_geo_place['results'][0] -- type dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negeri_district = test_geo_place['results'][0]['plus_code']['compound_code'].split(' ')\n",
    "negeri = negeri_district[-1]\n",
    "district = ' '.join(negeri_district[1:-1]).replace(',', ' ')\n",
    "\n",
    "print(negeri_district)\n",
    "print(\"NEGERI:\", negeri, \"DISTRICT:\", district)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```---------TEST ENDED-----```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "------SCRAP START-------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input required(test)\n",
    "food_keyword = ['restaurant', 'mcdonald', 'restoran', 'pizza', 'kfc', 'warung', 'food', 'eat', \n",
    "                'seafood', 'cuisine', 'fast food',\n",
    "                'supermarket', 'pasaraya', 'bakery', 'cafe',\n",
    "\n",
    "                'marketplace', 'market', \n",
    "                \n",
    "                'electronic store', 'furniture store', 'pet store', 'clothing', \n",
    "                \n",
    "                'dentist', 'doctor', 'pharmacy', 'health']\n",
    "\n",
    "negeri_keywords = ['Perak', 'Selangor', 'Pahang', 'Negeri Sembilan', 'Terengganu', 'Kedah', 'Kuala Lumpur', 'Lembah Klang',\n",
    "                    'Perlis', 'Kelantan', 'Johor', 'Melaka', 'Pulau Pinang', 'Putrajaya']\n",
    "\n",
    "johor_district = ['Batu Pahat','Johor Bahru','Kluang','Kota Tinggi','Kulai','Mersing','Muar','Pontian','Segamat','Tangkak',]\n",
    "kedah_district = ['Daerah Baling','Daerah Bandar Baharu','Kota Setar','Kuala Muda','Kubang Pasu','Kulim','Langkawi','Padang Terap','Pendang','Pokok Sena','Sik','Yan',]\n",
    "kelantan_district = ['Bachok','Gua Musang','Jeli','Kota Bharu','Kuala Krai','Machang','Pasir Mas','Pasir Puteh','Tanah Merah','Tumpat','Lojing',]\n",
    "melaka_district = ['Alor Gajah','Melaka Tengah','Jasin',]\n",
    "neg9_district = ['Jelebu','Jempol','Kuala Pilah','Port Dickson','Rembau','Tampin',]\n",
    "pahang_district = ['Bentong','Bera','Cameron Highland','Jerantut','Kuantan','Lipis','Maran','Pekan','Raub','Rompin','Temerloh',]\n",
    "pinang_district = ['Timur Laut','Barat Daya','Seberang Perai Utara','Seberang Perai Tengah','Seberang Perai Selatan',]\n",
    "perak_district = ['Batang Padang','Hilir Perak','Hulu Perak','Kampar','Kerian','Kinta''Kuala Kangsar','Larut, Matang dan Selama',\n",
    "                    'Manjung','Muallim','Perak Tengah','Daerah Bagan Datuk',]\n",
    "selangor_district = ['Gombak','Hulu Langat','Hulu Selangor','Klang','Kuala Langat','Kuala Selangor','Petaling','Sabak Bernam','Sepang']\n",
    "terengganu_district = ['Besut','Dungun','Hulu Terengganu','Kemaman','Kuala Terengganu','Marang','Setiu','Kuala Nerus']\n",
    "kl_district = ['Bukit Bintang','Titiwangsa' ,'Setiawangsa ','Wangsa Maju','Batu','Kepong','Segambut','Lembah Pantai' ,'Seputeh','Bandar Tun Razak','Cheras' ]\n",
    "perlis = ['perlis',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the data firstss\n",
    "all_info = []\n",
    "for keyword_1 in food_keyword:\n",
    "    for keyword in kl_district:\n",
    "\n",
    "        input_location = \"{0} in {1}\".format(keyword_1, keyword)\n",
    "        rad = 500\n",
    "        full_information = gm_geoloc.places(input_location, radius=rad)\n",
    "        full_info = full_information['results'] \n",
    "        all_info.append(full_info)\n",
    "\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"raw_info_negeri_KL.txt\", 'wb') as keep_in:\n",
    "    pickle.dump(all_info, keep_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"raw_info_negeri_KL.txt\", 'rb') as keep_in:\n",
    "    all_info = pickle.load(keep_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_info[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the sepcific information\n",
    "dict_info = {\"Name\":[], \"Latitude\":[], \"Longitude\":[], \"Address\": [], \n",
    "            \"Price_level\":[], \"Rating\":[], \"Types\":[], \"Daerah\":[], \"Negeri\":[]}\n",
    "\n",
    "for loc_list in all_info: # data is a dict\n",
    "    for data in loc_list:\n",
    "        # name: 'name'\n",
    "        name = data['name']\n",
    "        # adress: 'formatted_address'\n",
    "        address = data['formatted_address']\n",
    "        # coordinate: 'geometry' --> 'input_location\n",
    "        latitude = data['geometry']['location']['lat']\n",
    "        longitude = data['geometry']['location']['lng']\n",
    "\n",
    "        # negeri & daerah\n",
    "        if 'plus_code' in data:\n",
    "            negeri_district = data['plus_code']['compound_code'].split(' ')\n",
    "            negeri = negeri_district[-1]\n",
    "\n",
    "            # if NO daerah\n",
    "            if len(negeri_district) <= 2:\n",
    "                dict_info['Negeri'].append(negeri)\n",
    "                dict_info['Daerah'].append(np.NaN)\n",
    "            # if GOT daerah\n",
    "            elif len(negeri_district) > 2:\n",
    "                daerah = ' '.join(negeri_district[1:-1]).replace(',', '')\n",
    "                dict_info['Negeri'].append(negeri)\n",
    "                dict_info['Daerah'].append(daerah)\n",
    "\n",
    "        else:\n",
    "            dict_info[\"Negeri\"].append(np.NaN)\n",
    "            dict_info[\"Daerah\"].append(np.NaN)\n",
    "\n",
    "        # Price Level\n",
    "        if 'price_level' in data:\n",
    "            dict_info[\"Price_level\"].append(data['price_level'])\n",
    "        else:\n",
    "            dict_info[\"Price_level\"].append(np.NaN)\n",
    "            \n",
    "        # Rating\n",
    "        if 'rating' in data:\n",
    "            dict_info[\"Rating\"].append(data['rating'])\n",
    "        else:\n",
    "            dict_info[\"Rating\"].append(np.NaN)\n",
    "\n",
    "        # Types/label\n",
    "        if 'types' in data:\n",
    "            dict_info[\"Types\"].append(data['types'])\n",
    "        else:\n",
    "            dict_info[\"Types\"].append(np.NaN)\n",
    "\n",
    "        #appending\n",
    "        dict_info[\"Name\"].append(name)\n",
    "        dict_info[\"Latitude\"].append(str(latitude))\n",
    "        dict_info[\"Longitude\"].append(str(longitude))\n",
    "        dict_info[\"Address\"].append(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dict_info['Daerah']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` PICKLE ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"google_maps_scrap_KL.txt\", 'wb') as keep_in:\n",
    "    pickle.dump(dict_info, keep_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"google_maps_scrap_KL.txt\", 'rb') as keep_in:\n",
    "    dict_info = pickle.load(keep_in)\n",
    "\n",
    "#dict_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dict_info['Name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```PICKLE END```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```FINAL DATAFRAME```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = pd.DataFrame(dict_info, columns=dict_info.keys())\n",
    "df_copy = df_loc.copy()\n",
    "\n",
    "#df_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Pythonic method of LABELING PROCESS and locate it in new column\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged_it(x):\n",
    "    if \"food\" in x or 'restaurant' in x or 'bakery' in x or 'cafe' in x:\n",
    "        return \"food\"\n",
    "    elif 'dentist' in x or 'doctor' in x or 'health' in x:\n",
    "        return 'health'\n",
    "    elif 'electronic_store' in x or 'pet_store' in x or 'furniture_store' in x or 'pet_store' in x or 'clothing_store' in x:\n",
    "        return 'store'\n",
    "    elif 'supermarket' in x or 'shopping_mall' in x:\n",
    "        return 'market'\n",
    "    else:\n",
    "        return 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Label'] = df_copy['Types'].apply(lambda x: tagged_it(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Pythonic method end\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_excel('gmaps-data-KL.xlsx')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
